% !TeX spellcheck = en_GB

\begin{itemize}
	\item implementation in \gls{py} 3
	\item command line interface with subcommand as central entrypoint providing configuration and log management
	\item each process is run as separate processes to mitigate \gls{gil} limitations
	\item process has one task (agent simulator, collector, analyser module)
	\item modules/process pass messages mainly using \gls{amqp} and \gls{rabbitmq} as message broker
	\item reusing \gls{influxdb} and \gls{rabbitmq} by separating pipelines using a project name
\end{itemize}

\section{Basic Command Line Interface}
\label{sec:impl:cli}

\begin{itemize}
	\item central entry point for all operations
	\item consistent user experience -> less fiddling while debugging/developing
	\item centralises configuration and log setup
	\item can be easily made accessible via python setuptools
		\subitem if globally installed, callable via normal terminal command
	\item implemented using the \gls{lib-click} library version 6
\end{itemize}

\section{The Agent Simulator}
\label{sec:impl:agent}

\begin{itemize}
	\item simulates multiple agents based of one log containing telegram in raw \gls{baos} format. cf. Appendix~\todo{add log sample in appendix}
	\item log must be in chronological order
	\item utilizes own parser implementation \url{https://github.com/FreakyBytes/BaosKnxParser}
	\item different agents can be simulated by applying filter rules to log stream, defining, what each agent "can see"
	\item is supposed to replace actual agents during development
		\subitem repeatable data
		\subitem easy/fast setup
		\subitem log-time much faster than real-time
		\subitem load testing possible
	\item reads in individual pack
	\item filters according to agent filter rules
	\item updates agent-specific window data model
	\item if window length/timeout (cf. Section~\ref{sec:concept:agent}) is exceeded in log-time, windows are submitted to \gls{amqp} message broker (cf. Figure~\ref{fig:concept:architecture})
	\item runs until log is fully red, or maximum packets to parse are exceeded, or defined end timestamp is reached
\end{itemize}

\section{The Collector Module}
\label{sec:impl:collector}

\begin{itemize}
	\item central hub for relaying information
	\item receives agent windows via \gls{amqp} message broker (cf. Figure~\ref{fig:concept:architecture})
	\item subscribed to the agent topic using \gls{lib-pika} version 0.11
	\item incoming windows from agents are stored immediately in \gls{influxdb}
	\item every 4 seconds a callback \hint{(other word for callback?)} is called
	\item callback queries \gls{influxdb} for not relayed windows
		\subitem ordered latest first
		\subitem so a cumulating backlog does not affect the ability to show/process near-real-time metrics
		\subitem old windows will be processed once backlog decreases
	\item collector groups windows by timeslot
		\subitem so analysers receive a snapshot of the network
		\subitem allows them to analyse world-view without the need to compensate time-difference
\end{itemize}

\section{The Address Analyser Module}
\label{sec:impl:addr}

\begin{itemize}
	\item purpose is to detect the usage of prior unknown addresses
	\item (might) detect new (not malicious) devices
	\item stores all occurring source and destination addresses during the training period in a separately in a set
	\item set is stored to the disk using the standard \gls{py} \gls{json} serialiser
	\item during normal analytical operation the module checks if occurring addresses already occured in the training phase
	\item if not so counters are increased
	\item \todo{and list of unknown addresses is exported}
	\item exported metrics: \code{unknown\_src\_addr}, \code{unknown\_src\_telegrams}, \code{unknown\_dest\_addr}, \code{unknown\_dest\_telegrams}, \code{unknown\_addr}, \code{unknown\_telegrams}
\end{itemize}

\section{The Local Outlier Factor Analyser Module}
\label{sec:impl:lof}

