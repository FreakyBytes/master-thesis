% !TeX spellcheck = en_GB
Using the concepts described in Chapter~\ref{sec:concept}, a prototype was implemented to validate, test, and proof it, which is described in Chapter~\ref{sec:impl}.
In this Chapter this implementation shall be used to conduct a performance experiment on the implementation itself and the used algorithms.
For which first the experiment setup is described.

\section{Conducting the Performance Experiment}
\label{sec:results:experiment}

The in this thesis proposed concept for an online anomaly-based \gls{ids} tailored to \glspl{bas} was implemented as prototype, as described in Chapter~\ref{sec:impl}.
Using this prototype a full analysis pipeline was setup, which included the Collector, all four Analyser modules, and the Simulated Agent, as well as \gls{rabbitmq} as message-broker and \gls{influxdb} as persistent data storage.
The Simulated Agent was used to inject prior recorded traffic into the system faster than real time.
The data was originally recorded between 2017-01-21 and 2017-02-21 on the third floor of the computer science building of the University Rostock.
Before injecting and analysing the data, it was then split into three parts. The first two weeks are dedicated to train the baseline models for the Analyser modules. The following week was used as validation, to ensure the algorithms are properly fitted to the data. Finally, the last week was modified to contain four scenarios which alter the behaviour of the line, as described in Section~\ref{sec:methods:gen-test}.
\newpage
These modifications are meant to resemble plausible attacks on \gls{bas} networks and therefore include:

\begin{enumerate}
	\item Injecting unusual network traffic by copying traffic from another day and time
	\item Performing a \gls{dos} attack
	\item Scanning all addresses of the network
	\item Introducing two new devices
\end{enumerate}

First, only the training data was imported via the Simulated Agent and pushed to the \gls{influxdb} by the Collector. This data was then used to train the different algorithms.
Then the remaining two parts of dataset were imported via the Simulated Agent and processed into statistical windows, these were then processed by the Collector, and relayed to the analytical modules. Finally, the Analyser compare the incoming windows to the baseline model and store the result in the \gls{influxdb}. From there the monitoring and alerting software \gls{grafana} can query the results and plot them into dynamic graphs, as well as send alerts based on predefined thresholds or rules.

During the import of the test dataset an increasing delay of processing for queries to the \gls{influxdb} was observed. A cause could not be determined, as the queries itself and the length of the queried data did not change over the course of the experiment.
Further, the \gls{lof} Analyser module required more processing time as its counterparts, which was easily mitigated by scaling the \gls{lof} Analyser.

In this experiment the feature to simulate multiple Agents, using filter rules, was not used due to the fact that the dataset was merely recorded on one single line. Therefore, a further separation seemed unfeasible, as it would complicate the evaluation of the detection results without providing more insights.

\section{Experiment Results}
\label{sec:results:results}

Finally, in this section the detection results of the proposed algorithms are examined using the graphs generated with \gls{grafana}. They will be used to determine the quality of the detection results based on five criteria:

\begin{enumerate}
	\item General ability to the detect the attack
	\item Differentiation from background noise of the detection results
	\begin{enumerate}
		\item Average difference in detected outliers compared to the validation dataset
		\item Average difference in underlying decision metric compared to the validation dataset
	\end{enumerate}
	\item Response time 
	\item Persistence of detection
\end{enumerate}

These criteria will be evaluated by interpreting six different plots exported from the monitoring and alerting solution \gls{grafana}.
The first plot (a) shows the amount of telegrams per window over time as green staircase plot. Additionally the amount of telegrams using an unknown address (either as source or destination) are plotted in yellow.
The second graph (b) builds onto this and indicates how many unique unknown addresses per window were found over time, separated by source addresses (green) and destination addresses (yellow).
Third (c) the number of windows considered outliers over time is shown, detected by the \gls{svm} (red) and using the \gls{lof} (blue). Whereby not single telegrams are evaluated but entire windows.
The fourth plot (d) displays the calculated entropy per window over time.
Finally, the fifth (e) and sixth (f) graph show the spread (difference between minimum and maximum) and average of the underlying metric for the \gls{lof} and the \gls{svm}.
In case of the \gls{lof} lower values indicate outlying observations. In case of the \gls{svm} the graph depicts the distance from the decision surface. Whereby a negative distance indicates an observation outside the borders of normality, an outlier, and a positive distance indicates and inlier. The higher the distance is, the more distinct is the classification.
As as general rule, a smaller spread suggests a clearer decision or tendency towards inlier or outlier over multiple windows.

The distinction by Agents can be ignored, as only one Agent was simulated in this experiment. 

\subsection{Detection of Unusual Network Traffic}
\label{sec:results:results:unusual}

The first modification applied to the test dataset was the injection of unusual traffic. 
For this a time span of five hours was replaced with traffic from the same line, but from different weekday and time of the day.
This effectively aims to test the seasonal- or time-sensitivity of the models.

Figure~\ref{fig:results:unusual} shows several metrics from the four different anomaly detection methods.
In \ref{fig:results:unusual:tc} a sudden increase in the observed amounts of telegrams per window is to observe, whereby no telegrams using unknown addresses were observed. This is to be expected since the five hours which replaced the original traffic were taken from the same line but from a more busy point of the week, hence the increase of transmitted telegrams.
The absence of unknown addresses, either as source or as destination, is also clearly indicated by Figure~\ref{fig:results:unusual:addr}.

Surprisingly, there is also no significant increase in the number of detected outliers neither by the \gls{svm}, nor using the \gls{lof}, as shown in Figure~\ref{fig:results:unusual:outlier}.
Even though the \gls{lof} shows an average of $0.77$ outliers, it can hardly be considered a significant increase when compared to the surrounding unmodified data and to the validation dataset in Appendix~\ref{app:metrics:validation}.
However, the spread of the \gls{lof} depicted in Figure~\ref{fig:results:unusual:lof} shows a small change downwards, which indicates less normal behaviour -- it is arguably not significant enough.

In contrast, Figure~\ref{fig:results:unusual:svm} even shows that the distance to the decision function of the \gls{svm} increases positively, which means the analysed points are considered to represent the normality stronger. This is also reflected in the detection of no outliers with the exception of two small peaks.

The Entropy Analyser mostly calculates a entropy of infinity, which is here encoded as $100000$. This results is not limited to the period of the modification and therefore renders its results relatively meaningless.

\begin{figure}[H]
	\newcommand{\figwith}{0.49\textwidth}
	\newcommand{\figprefix}{unusual}
	\centering
	
	\begin{subfigure}[b]{\figwith}
		\includegraphics[width=\textwidth]{figures/700-results/\figprefix-tc.png}
		\caption{Telegrams (green) and telegrams with unknown addresses (yellow) over time}
		\label{fig:results:\figprefix:tc}
	\end{subfigure}
	\hfil
	\begin{subfigure}[b]{\figwith}
		\includegraphics[width=\textwidth]{figures/700-results/\figprefix-unknown-addr.png}
		\caption{Amount of observed unknown source (green) and destination (yellow) addresses}
		\label{fig:results:\figprefix:addr}
	\end{subfigure}
	\\[1.5mm]
	\begin{subfigure}[b]{\figwith}
		\includegraphics[width=\textwidth]{figures/700-results/\figprefix-num-outliers.png}
		\caption{Number of detected outliers via SVM (red) and LOF (blue).}
		\label{fig:results:\figprefix:outlier}
	\end{subfigure}
	\hfil
	\begin{subfigure}[b]{\figwith}
		\includegraphics[width=\textwidth]{figures/700-results/\figprefix-entropy.png}
		\caption{Calculated Entropy over time, infinity is encoded as $100 000$}
		\label{fig:results:\figprefix:entropy}
	\end{subfigure}
	\\[1.5mm]
	\begin{subfigure}[b]{\figwith}
		\includegraphics[width=\textwidth]{figures/700-results/\figprefix-lof-spread.png}
		\caption{Spread and average of the Local Outlier Factor, smaller numbers indicate outlier}
		\label{fig:results:\figprefix:lof}
	\end{subfigure}
	\hfil
	\begin{subfigure}[b]{\figwith}
		\includegraphics[width=\textwidth]{figures/700-results/\figprefix-svm-spread.png}
		\caption{Spread and average of the distance to decision surface, negative distances are outlier}
		\label{fig:results:\figprefix:svm}
	\end{subfigure}
	
	\caption[Detection results of unusual network traffic]{Detection results of unusual network traffic from 2017-02-12 02:00 to 09:00 with a minimal time resolution of 2 minutes. The modified time range is marked as a grey box.}
	\label{fig:results:\figprefix}
	
\end{figure}

\begin{table}[H]
	\aboverulesep=0ex
	\belowrulesep=0ex
	\renewcommand{\arraystretch}{1.2}
	\newcolumntype{Y}{>{\centering\arraybackslash}X}
	
	\centering
	\begin{tabularx}{0.95\textwidth}{|l|Y|Y|Y|Y|}
		\toprule
		& \gls{lof} & \gls{svm} & Address & Entropy \\\midrule
		1. Attack detected & no & no & no & no \\\midrule
		2.a) Avg. difference in outliers  & $0.319$ & $0.013$ & 0 & n/a \\\midrule
		2.b) Avg. difference in metric & $2.65$ & $5.42$ & n/a & n/a \\\midrule
		3. Response time & 0s & 0s & n/a & n/a \\\midrule
		4. Persistence & n/a & n/a & n/a & n/a \\\bottomrule
	\end{tabularx}
	\caption[Detection results of unusual traffic]{Detection results of unusual traffic. Averages are compared to the validation dataset.}
	\label{tab:results:unusual}
\end{table}

\subsection{Detection of a DoS Attack}
\label{sec:results:results:dos}

The second modification applied to the test dataset, included a \gls{dos} attack, which flooded the entire line \code{3.4} with \code{A\_Restart} telegrams. As expect the amount of telegrams with unknown addresses and count of unknown addresses increase rapidly, as shown in Figure~\ref{fig:results:dos:tc} and~\ref{fig:results:dos:addr}. This clearly indicates an anomaly, since the threshold for unknown addresses within the network should be set to zero.

Figure~\ref{fig:results:dos:outlier} illustrates, that the \gls{lof} and \gls{svm} outlier detection reacted equally prompt, by both classifying all windows during the entire period of the attack as outlier.
This is also reflected by the underlying metrics. The maximum of the \gls{lof} in Figure~\ref{fig:results:dos:lof} stays low during the entire attack. Similarly, the distance to the decision surface of the \gls{svm} resides in the high negatives implying a huge divergence from the normality.
Especially noteworthy is that the spread between minimum and maximum of the Local Outlier Factor as well as the distance to the decision surface falls close to zero during the attack, which indicates a high certainty of the classification.
The premature identification of the anomalies visible in Figure~\ref{fig:results:dos:outliers} could be caused by misalignment and small inaccuracies in the time windowing processes performed by the Collector.

The entropy, plotted in Figure~\ref{fig:results:dos:entropy}, does not change at all, neither during the modification nor outside of it.

\begin{figure}[H]
	\newcommand{\figwith}{0.49\textwidth}
	\newcommand{\figprefix}{dos}
	\centering
	
	\begin{subfigure}[b]{\figwith}
		\includegraphics[width=\textwidth]{figures/700-results/\figprefix-tc.png}
		\caption{Telegrams (green) and telegrams with unknown addresses (yellow) over time}
		\label{fig:results:\figprefix:tc}
	\end{subfigure}
	\hfil
	\begin{subfigure}[b]{\figwith}
		\includegraphics[width=\textwidth]{figures/700-results/\figprefix-unknown-addr.png}
		\caption{Amount of observed unknown source (green) and destination (yellow) addresses}
		\label{fig:results:\figprefix:addr}
	\end{subfigure}
	\\[1.5mm]
	\begin{subfigure}[b]{\figwith}
		\includegraphics[width=\textwidth]{figures/700-results/\figprefix-num-outliers.png}
		\caption{Number of detected outliers via SVM (red) and LOF (blue).}
		\label{fig:results:\figprefix:outlier}
	\end{subfigure}
	\hfil
	\begin{subfigure}[b]{\figwith}
		\includegraphics[width=\textwidth]{figures/700-results/\figprefix-entropy.png}
		\caption{Calculated Entropy over time, infinity is encoded as $100 000$}
		\label{fig:results:\figprefix:entropy}
	\end{subfigure}
	\\[1.5mm]
	\begin{subfigure}[b]{\figwith}
		\includegraphics[width=\textwidth]{figures/700-results/\figprefix-lof-spread.png}
		\caption{Spread and average of the Local Outlier Factor, smaller numbers indicate outlier}
		\label{fig:results:\figprefix:lof}
	\end{subfigure}
	\hfil
	\begin{subfigure}[b]{\figwith}
		\includegraphics[width=\textwidth]{figures/700-results/\figprefix-svm-spread.png}
		\caption{Spread and average of the distance to decision surface, negative distances are outlier}
		\label{fig:results:\figprefix:svm}
	\end{subfigure}
	
	\caption[Detection results of the DoS attack]{Detection results DoS attack from 2017-02-13 08:40 to 09:50 with a minimal time resolution of 2 minutes. The time range of the attack is marked as a grey box.}
	\label{fig:results:\figprefix}
	
\end{figure}

\begin{table}[H]
	\aboverulesep=0ex
	\belowrulesep=0ex
	\renewcommand{\arraystretch}{1.2}
	\newcolumntype{Y}{>{\centering\arraybackslash}X}
	
	\centering
	\begin{tabularx}{0.95\textwidth}{|l|Y|Y|Y|Y|}
		\toprule
		& \gls{lof} & \gls{svm} & Address & Entropy \\\midrule
		1. Attack detected & yes & yes & yes & no \\\midrule
		2.a) Avg. difference in outliers  & $0.549$ & $0.997$ & $254$ & n/a \\\midrule
		2.b) Avg. difference in metric & $-1.730$ & $-39.46$ & n/a & n/a \\\midrule
		3. Response time & 0s & 0s & 0s & n/a \\\midrule
		4. Persistence & $100$\% & $100$\% & $100$\% & n/a \\\bottomrule
	\end{tabularx}
	\caption[Detection results of the DoS attack]{Detection results of the \gls{dos} attack.}
	\label{tab:results:dos}
\end{table}

\subsection{Detection of a Network Scan}
\label{sec:results:results:scan}

The third modification to be applied to the test dataset is a network scan where the entire \gls{knx} address space was scanned using a management routine every \gls{knx} device must implement. Every present device would respond with an appropriator answer.

Similar to the \gls{dos} attack a scan of the entire network produces significantly more traffic than normal operation, which is indicated by Figure~\ref{fig:results:scan:tc}. Further, a lot of traffic targeting prior unknown addresses is inevitable, causing the Address Analyser to detect such behaviour. (see Figure~\ref{fig:results:scan:addr})

In contrast to the clear identification by the Address Analyser stands the \gls{lof} Analyser, which identifies the attack as outlier in Figure~\ref{fig:results:scan:outlier}, but the separation from the background noise is not significant. Similar behaviour is to be observed in the underlying \gls{lof} metric depicted in Figure~\ref{fig:results:scan:lof}. However, it is curious that even though the average of the \gls{lof} is stable compared with the surrounding background noise, the spread decreases drastically.

On the other hand, the \gls{svm} identifies the threat flawless. The low background noise and the clear detection as outlier in Figure~\ref{fig:results:scan:outlier} allows for a positive identification. This is supported by a sharp drop into the negative of the distance to the decision surface as shown in Figure~\ref{fig:results:scan:svm}, distinctly indicating outlier.

The calculated entropy compared to the training data is continuously infinite, making it unfit to draw any conclusions from.


\begin{figure}[H]
	\newcommand{\figwith}{0.49\textwidth}
	\newcommand{\figprefix}{scan}
	\centering
	
	\begin{subfigure}[b]{\figwith}
		\includegraphics[width=\textwidth]{figures/700-results/\figprefix-tc.png}
		\caption{Telegrams (green) and telegrams with unknown addresses (yellow) over time}
		\label{fig:results:\figprefix:tc}
	\end{subfigure}
	\hfil
	\begin{subfigure}[b]{\figwith}
		\includegraphics[width=\textwidth]{figures/700-results/\figprefix-unknown-addr.png}
		\caption{Amount of observed unknown source (green) and destination (yellow) addresses}
		\label{fig:results:\figprefix:addr}
	\end{subfigure}
	\\[1.5mm]
	\begin{subfigure}[b]{\figwith}
		\includegraphics[width=\textwidth]{figures/700-results/\figprefix-num-outliers.png}
		\caption{Number of detected outliers via SVM (red) and LOF (blue).}
		\label{fig:results:\figprefix:outlier}
	\end{subfigure}
	\hfil
	\begin{subfigure}[b]{\figwith}
		\includegraphics[width=\textwidth]{figures/700-results/\figprefix-entropy.png}
		\caption{Calculated Entropy over time, infinity is encoded as $100 000$}
		\label{fig:results:\figprefix:entropy}
	\end{subfigure}
	\\[1.5mm]
	\begin{subfigure}[b]{\figwith}
		\includegraphics[width=\textwidth]{figures/700-results/\figprefix-lof-spread.png}
		\caption{Spread and average of the Local Outlier Factor, smaller numbers indicate outlier}
		\label{fig:results:\figprefix:lof}
	\end{subfigure}
	\hfil
	\begin{subfigure}[b]{\figwith}
		\includegraphics[width=\textwidth]{figures/700-results/\figprefix-svm-spread.png}
		\caption{Spread and average of the distance to decision surface, negative distances are outlier}
		\label{fig:results:\figprefix:svm}
	\end{subfigure}
	
	\caption[Detection results of the network scan]{Detection results of the network scan from 2017-02-13 20:45 to 21:17 with a minimal time resolution of 30 seconds. The time range of the attack is marked as a grey box.}
	\label{fig:results:\figprefix}
	
\end{figure}

\begin{table}[H]
	\aboverulesep=0ex
	\belowrulesep=0ex
	\renewcommand{\arraystretch}{1.2}
	\newcolumntype{Y}{>{\centering\arraybackslash}X}
	
	\centering
	\begin{tabularx}{0.95\textwidth}{|l|Y|Y|Y|Y|}
		\toprule
		& \gls{lof} & \gls{svm} & Address & Entropy \\\midrule
		1. Attack detected & no & yes & yes & no \\\midrule
		2.a) Avg. difference in outliers  & $0.029$ & $0.549$ & $5 \cdot 10^{3}$ & n/a \\\midrule
		2.b) Avg. difference in metric & $-2.10$ & $-32.97$ & n/a & n/a \\\midrule
		3. Response time & n/a & 0s & 0s & n/a \\\midrule
		4. Persistence & n/a & $100$\% & $100$\% & n/a \\\bottomrule
	\end{tabularx}
	\caption[Detection results of the network scan]{Detection results of the network scan.}
	\label{tab:results:scan}
\end{table}

\subsection{Detection of New Devices}
\label{sec:results:results:newdevice}

The fourth and final modification applied to the test dataset contained two new devices. The required data was taken from the same line, but from a different day, only the date and the source address were altered. This traffic was injected during the whole target day, keeping the frequency of the original traffic.

As traffic resembling an actual \gls{knx} device was injected using prior not used addresses, the graph in Figure~\ref{fig:results:newdevice:tc} shows only small amounts traffic with unknown addresses, when compared to \gls{dos} attacks or network scans.
However, Figure~\ref{fig:results:newdevice:addr} illustrates clearly activity with of unknown devices.
Since the alert threshold for both metrics is zero, an alert would be raised.

Opposed to that are the results of the outlier detection using \gls{lof} and the \gls{svm}, as shown in Figure~\ref{fig:results:newdevice:outlier}.
With only a difference of $0.055$ compared to the validation dataset no significant increase in outliers was detected by the \gls{lof} Analyser.
Similarly, the \gls{svm} identified on average $0.005$ outliers over the period of modification, which resembles a drop of $0.002$ when compared to the validation dataset.
Additionally, the spread for both the \gls{lof} and the distance to the decision surface in Figure~\ref{fig:results:newdevice:lof} and~\ref{fig:results:newdevice:svm} is considerably moderate, not indicating a strong tendency to either outlier or inlier.
Therefore, it is to conclude that neither the \gls{lof} nor the \gls{svm} detected this modification.
Although the occurrence of unknown addresses and outliers detected by the \gls{svm} show some timely correlation.

As in the previous modifications, no conclusion can be drawn from the Entropy Analyser as it is continuously detecting an infinite value.

The persistence and response time can not be taken into account for this modification. Even though the modification was applied over the course of the whole day, the device were not sending traffic right from the beginning of the day, therefore not being detectable on any layer above the physical.

\begin{figure}[H]
	\newcommand{\figwith}{0.49\textwidth}
	\newcommand{\figprefix}{newdevice}
	\centering
	
	\begin{subfigure}[b]{\figwith}
		\includegraphics[width=\textwidth]{figures/700-results/\figprefix-tc.png}
		\caption{Telegrams (green) and telegrams with unknown addresses (yellow) over time}
		\label{fig:results:\figprefix:tc}
	\end{subfigure}
	\hfil
	\begin{subfigure}[b]{\figwith}
		\includegraphics[width=\textwidth]{figures/700-results/\figprefix-unknown-addr.png}
		\caption{Amount of observed unknown source (green) and destination (yellow) addresses}
		\label{fig:results:\figprefix:addr}
	\end{subfigure}
	\\[1.5mm]
	\begin{subfigure}[b]{\figwith}
		\includegraphics[width=\textwidth]{figures/700-results/\figprefix-num-outliers.png}
		\caption{Number of detected outliers via SVM (red) and LOF (blue).}
		\label{fig:results:\figprefix:outlier}
	\end{subfigure}
	\hfil
	\begin{subfigure}[b]{\figwith}
		\includegraphics[width=\textwidth]{figures/700-results/\figprefix-entropy.png}
		\caption{Calculated Entropy over time, infinity is encoded as $100 000$}
		\label{fig:results:\figprefix:entropy}
	\end{subfigure}
	\\[1.5mm]
	\begin{subfigure}[b]{\figwith}
		\includegraphics[width=\textwidth]{figures/700-results/\figprefix-lof-spread.png}
		\caption{Spread and average of the Local Outlier Factor, smaller numbers indicate outlier}
		\label{fig:results:\figprefix:lof}
	\end{subfigure}
	\hfil
	\begin{subfigure}[b]{\figwith}
		\includegraphics[width=\textwidth]{figures/700-results/\figprefix-svm-spread.png}
		\caption{Spread and average of the distance to decision surface, negative distances are outlier}
		\label{fig:results:\figprefix:svm}
	\end{subfigure}
	
	\caption[Detection results of new devices]{Detection results of new devices from 2017-02-13 23:00 to 2017-02-15 01:00 with a minimal time resolution of 10 minutes. The time range of the modification is marked as a grey box.}
	\label{fig:results:\figprefix}
	
\end{figure}

\begin{table}[H]
	\aboverulesep=0ex
	\belowrulesep=0ex
	\renewcommand{\arraystretch}{1.2}
	\newcolumntype{Y}{>{\centering\arraybackslash}X}
	
	\centering
	\begin{tabularx}{0.95\textwidth}{|l|Y|Y|Y|Y|}
		\toprule
		& \gls{lof} & \gls{svm} & Address & Entropy \\\midrule
		1. Attack detected & no & no & yes & no \\\midrule
		2.a) Avg. difference in outliers  & $0.055$ & $-0.002$ & $0.03$ & n/a \\\midrule
		2.b) Avg. difference in metric & $0.32$ & $-0.13$ & n/a & n/a \\\midrule
		3. Response time & n/a & ($4.5$h) & ($6.83$h) & n/a \\\midrule
		4. Persistence & n/a & ($0.54$\%) & ($3.23$\%) & n/a \\\bottomrule
	\end{tabularx}
	\caption[Detection results of new devices]{Detection results of two new devices in the network.}
	\label{tab:results:newdevice}
\end{table}

\section{Summary of the Detection Results}
\label{sec:results:summary}

\begin{comment}
\begin{itemize}
	\item 3 out of 4 attacks were successfully detected
	\item 2 of those by machine learning algorithms
	\item to note, that lof and svm were trained with normalised data
		\subitem traffic rates not into account
		\subitem only change in composition/structure can be recognised
		\subitem changes in transmission rate should be monitored in Grafana
		
	\item \gls{svm} is the best performing algo
		\subitem low background noise
		\subitem detected both direct attacks
		\subitem sharp decision surface
		\subitem small model, quick detection/estimation
		\subitem model training is computational intensive
				
	\item \gls{lof} does not perform well
		\subitem requires at least further tuning
		\subitem high background noise (cf. Figure~\ref{fig:results:validation:outlier})
		\subitem detected only \gls{dos} reliably
		\subitem almost detected scan, but was not clear distinguishable from background noise
		\subitem large model, longer computation time for detection
		\subitem nearest neighbour search is perform every time -> computational heavy, especially for large datasets
		
	\item addr analyser
		\subitem simple method to any drastic change involving unknown addresses in the network
		\subitem good supplement
		\subitem low resource overhead: small model, quick detection, fast training
	
	\item entropy was useless
		\subitem mostly entropy of inf calculated
\end{itemize}
\end{comment}

Altogether, three out of four attack scenarios could be detected using a variety of algorithms, as summarised in Table~\ref{tab:results:conclusion}. Two of those would have been detected using the unsupervised machine learning algorithms \gls{lof} and \gls{svm}.
It is to note that both rely on the feature vector and operated on normalised data, which correspondingly does not account for absolute values.
Under those circumstances only the change in composition or structure of the traffic can be recognised by these algorithms. As effect they can handle changing window lengths without requiring re-training.
Also, as stated earlier absolute changes in e.g. transmission rate can be monitored easily in exiting monitoring and alerting solutions.

Another module relying on the feature vector and normalised data is the Entropy Analyser.
In contrast to the \gls{lof} and \gls{svm} it was not able any of the four modifications. Moreover, it calculated an infinite entropy for almost the entire dataset, which would represent an infinite information gain. (cf. Figure~\ref{fig:results:validation:entropy})
This behaviour might be caused by a extremely high sensitivity, but renders the results of this Analyser modules useless.

\begin{table}[h]
	\aboverulesep=0ex
	\belowrulesep=0ex
	\renewcommand{\arraystretch}{1.2}
	\newcolumntype{Y}{>{\centering\arraybackslash}X}
	
	\centering
	\begin{tabularx}{0.95\textwidth}{|l|Y|Y|Y|Y|}
		\toprule
		& \gls{lof} & \gls{svm} & Address & Entropy \\\midrule
		Unusual traffic & no & no & no & no \\\midrule
		\gls{dos} attack & yes & yes & yes & no \\\midrule
		Network Scan & no & yes & yes & no \\\midrule
		New Devices & no & no & yes & no \\\midrule
	\end{tabularx}
	\caption[Summary of detection results]{Summary of detection results.}
	\label{tab:results:conclusion}
\end{table}

On the other end of the spectrum resides the \gls{svm} Analyser. It detected both direct attacks reliably and outputs relatively low background noise and false-positives, therefore providing a sharp decision surface.
The trained model consumes with $504 KiB$ comparably less disk space and shows fast classification results. Although, the training process proved to be computational more intensive.

Proceeding, the \gls{lof} Analyser required further adjustments as it only detected on attack reliably.
It shows high amount of background noise and false-positives. (cf. Figure~\ref{fig:results:validation:outlier}) The detection of the \gls{dos} attack was clearly identifiable and also for the network scan a change in pattern of the \gls{lof} output could be observed, but was not explicitly distinguishable from the background noise.
Further, during the experiment it was observed that the classification with \gls{lof} takes the longest among all algorithms, which was counteracted by scaling this Analyser Module.
Moreover, the trained model requires the most disk space with $151 MiB$, even though the training process is not computational intensive.

Lastly, the Address Analyser does not rely on the feature vector, it rather compares the observed addresses to a pre-trained list of known addresses. This is a good supplement and an easy way to discover new unknown devices and also to recognise attacks like network scans, which relies on probing all addresses within a specific range.
By relying on this simple working principle it only requires a small model with $1.4 KiB$ and is not computational intensive, neither during training nor operation.

In conclusion, the \gls{svm} Analyser seems to be the most proficient choice among the machine learning approaches. It stands out by detecting the most attacks clearly and with low background noise. Further, the trained model is small in size making it rather portable. 
In comparison to the \gls{svm} Analyser, the results of the \gls{lof} module are characterised by high background noise. The \gls{lof} metric itself, however, suggests potential to reduce this noise and increase the clarity of detection, if the algorithm can be tuned more.
Furthermore, it seems to be rather implausible to utilise the Entropy Analyser in the here presented form, as it is not fit to evaluate or detect any kind of anomaly.
In contrast to the machine learning approaches the Address Analyser focusses on one specific feature and archives even better detection results than the \gls{svm} Analyser, when the attack involves unknown addresses.
